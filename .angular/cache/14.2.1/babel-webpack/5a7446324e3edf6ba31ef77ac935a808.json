{"ast":null,"code":"import { NgZone } from '@angular/core';\nimport { merge, of, Subject } from 'rxjs';\nimport { map, tap } from 'rxjs/operators';\nimport { defaultLanguage, languages } from '../shared/model/languages';\nimport { SpeechError } from '../shared/model/speech-error';\nimport { SpeechEvent } from '../shared/model/speech-event';\nimport { environment } from 'src/environments/environment';\nimport * as i0 from \"@angular/core\";\nimport * as i1 from \"../shared/services/web-apis/speech-recognizer.service\";\nimport * as i2 from \"../shared/services/actions/action-context\";\nimport * as i3 from \"../helper\";\nimport * as i4 from \"@angular/common\";\nimport * as i5 from \"@angular/material/button\";\nimport * as i6 from \"@angular/material/card\";\nimport * as i7 from \"@angular/material/form-field\";\nimport * as i8 from \"@angular/material/input\";\nimport * as i9 from \"@angular/material/icon\";\nimport * as i10 from \"@angular/material/select\";\nimport * as i11 from \"@angular/material/core\";\n\nfunction WebSpeechComponent_mat_card_1_Template(rf, ctx) {\n  if (rf & 1) {\n    i0.ɵɵelementStart(0, \"mat-card\", 9);\n    i0.ɵɵtext(1);\n    i0.ɵɵelementEnd();\n  }\n\n  if (rf & 2) {\n    const errorMessage_r6 = ctx.ngIf;\n    i0.ɵɵadvance(1);\n    i0.ɵɵtextInterpolate(errorMessage_r6);\n  }\n}\n\nfunction WebSpeechComponent_mat_option_8_Template(rf, ctx) {\n  if (rf & 1) {\n    const _r9 = i0.ɵɵgetCurrentView();\n\n    i0.ɵɵelementStart(0, \"mat-option\", 10);\n    i0.ɵɵlistener(\"click\", function WebSpeechComponent_mat_option_8_Template_mat_option_click_0_listener() {\n      const restoredCtx = i0.ɵɵrestoreView(_r9);\n      const language_r7 = restoredCtx.$implicit;\n      const ctx_r8 = i0.ɵɵnextContext();\n      return i0.ɵɵresetView(ctx_r8.selectLanguage(language_r7));\n    });\n    i0.ɵɵtext(1);\n    i0.ɵɵelementEnd();\n  }\n\n  if (rf & 2) {\n    const language_r7 = ctx.$implicit;\n    i0.ɵɵproperty(\"value\", language_r7);\n    i0.ɵɵadvance(1);\n    i0.ɵɵtextInterpolate1(\" \", language_r7, \" \");\n  }\n}\n\nfunction WebSpeechComponent_button_10_Template(rf, ctx) {\n  if (rf & 1) {\n    const _r11 = i0.ɵɵgetCurrentView();\n\n    i0.ɵɵelementStart(0, \"button\", 11);\n    i0.ɵɵlistener(\"click\", function WebSpeechComponent_button_10_Template_button_click_0_listener() {\n      i0.ɵɵrestoreView(_r11);\n      const ctx_r10 = i0.ɵɵnextContext();\n      return i0.ɵɵresetView(ctx_r10.stop());\n    });\n    i0.ɵɵelementStart(1, \"mat-icon\", 12);\n    i0.ɵɵtext(2, \"mic\");\n    i0.ɵɵelementEnd()();\n  }\n}\n\nfunction WebSpeechComponent_ng_template_12_Template(rf, ctx) {\n  if (rf & 1) {\n    const _r13 = i0.ɵɵgetCurrentView();\n\n    i0.ɵɵelementStart(0, \"button\", 11);\n    i0.ɵɵlistener(\"click\", function WebSpeechComponent_ng_template_12_Template_button_click_0_listener() {\n      i0.ɵɵrestoreView(_r13);\n      const ctx_r12 = i0.ɵɵnextContext();\n      return i0.ɵɵresetView(ctx_r12.start());\n    });\n    i0.ɵɵelementStart(1, \"mat-icon\");\n    i0.ɵɵtext(2, \"mic\");\n    i0.ɵɵelementEnd()();\n  }\n}\n\nfunction WebSpeechComponent_section_14_Template(rf, ctx) {\n  if (rf & 1) {\n    i0.ɵɵelementStart(0, \"section\")(1, \"mat-card\", 13);\n    i0.ɵɵtext(2);\n    i0.ɵɵpipe(3, \"async\");\n    i0.ɵɵelementEnd()();\n  }\n\n  if (rf & 2) {\n    const ctx_r5 = i0.ɵɵnextContext();\n    i0.ɵɵadvance(2);\n    i0.ɵɵtextInterpolate(i0.ɵɵpipeBind1(3, 1, ctx_r5.transcript$));\n  }\n}\n\nexport let WebSpeechComponent = /*#__PURE__*/(() => {\n  class WebSpeechComponent {\n    constructor(speechRecognizer, actionContext, helper, ngZone) {\n      this.speechRecognizer = speechRecognizer;\n      this.actionContext = actionContext;\n      this.helper = helper;\n      this.ngZone = ngZone;\n      this.languages = languages;\n      this.currentLanguage = defaultLanguage;\n      this.totalResult = '';\n      this.defaultError$ = new Subject();\n      this.BACKEND_SERVER_URL = environment.base_url;\n    }\n\n    ngOnInit() {\n      const webSpeechReady = this.speechRecognizer.initialize(this.currentLanguage);\n\n      if (webSpeechReady) {\n        this.initRecognition();\n      } else {\n        this.errorMessage$ = of('Your Browser is not supported. Please try Google Chrome.');\n      }\n    }\n\n    start() {\n      if (this.speechRecognizer.isListening) {\n        this.stop();\n        return;\n      }\n\n      this.defaultError$.next(undefined);\n      this.speechRecognizer.start();\n    }\n\n    stop() {\n      this.speechRecognizer.stop();\n    }\n\n    selectLanguage(language) {\n      if (this.speechRecognizer.isListening) {\n        this.stop();\n      }\n\n      this.currentLanguage = language;\n      this.speechRecognizer.setLanguage(this.currentLanguage);\n    }\n\n    initRecognition() {\n      this.transcript$ = this.speechRecognizer.onResult().pipe(tap(notification => {\n        this.processNotification(notification);\n      }), map(notification => notification.content || ''));\n      this.listening$ = merge(this.speechRecognizer.onStart(), this.speechRecognizer.onEnd()).pipe(map(notification => notification.event === SpeechEvent.Start));\n      this.errorMessage$ = merge(this.speechRecognizer.onError(), this.defaultError$).pipe(map(data => {\n        if (data === undefined) {\n          return '';\n        }\n\n        if (typeof data === 'string') {\n          return data;\n        }\n\n        let message;\n\n        switch (data.error) {\n          case SpeechError.NotAllowed:\n            message = `Cannot run the demo.\n            Your browser is not authorized to access your microphone.\n            Verify that your browser has access to your microphone and try again.`;\n            break;\n\n          case SpeechError.NoSpeech:\n            message = `No speech has been detected. Please try again.`;\n            break;\n\n          case SpeechError.AudioCapture:\n            message = `Microphone is not available. Plese verify the connection of your microphone and try again.`;\n            break;\n\n          default:\n            message = '';\n            break;\n        }\n\n        return message;\n      }));\n    }\n\n    processNotification(notification) {\n      if (notification.event === SpeechEvent.FinalContent) {\n        const message = notification.content?.trim() || '';\n        this.actionContext.processMessage(message, this.currentLanguage); // this.actionContext.runAction(message, this.currentLanguage);\n\n        this.totalTranscript = this.totalTranscript ? `${this.totalTranscript}\\n${message}` : notification.content;\n        this.stop();\n        this.sendToServer(notification.content);\n      }\n    }\n\n    sendToServer(queryText) {\n      if (queryText && queryText.trim() !== \"\") {\n        let json = {\n          queryData: queryText\n        };\n        this.helper.httpMethodRequester(\"POST\", '/api/gpt', json, true, true, response_data => {\n          console.log(response_data);\n\n          if (response_data.success && response_data.filePath) {\n            this.ngZone.run(() => {\n              this.totalResult += response_data.answer;\n            });\n            let audio = new Audio();\n            audio.src = `${this.BACKEND_SERVER_URL}/${response_data.filePath}`;\n            audio.load();\n            audio.play();\n          } else {\n            console.log(\"sendToServer Error from Server\");\n          }\n        });\n      }\n    }\n\n  }\n\n  WebSpeechComponent.ɵfac = function WebSpeechComponent_Factory(t) {\n    return new (t || WebSpeechComponent)(i0.ɵɵdirectiveInject(i1.SpeechRecognizerService), i0.ɵɵdirectiveInject(i2.ActionContext), i0.ɵɵdirectiveInject(i3.Helper), i0.ɵɵdirectiveInject(i0.NgZone));\n  };\n\n  WebSpeechComponent.ɵcmp = /*@__PURE__*/i0.ɵɵdefineComponent({\n    type: WebSpeechComponent,\n    selectors: [[\"wsa-web-speech\"]],\n    decls: 22,\n    vars: 14,\n    consts: [[\"class\", \"notification\", 4, \"ngIf\"], [3, \"value\", \"valueChange\"], [3, \"value\", \"click\", 4, \"ngFor\", \"ngForOf\"], [\"mat-fab\", \"\", 3, \"click\", 4, \"ngIf\", \"ngIfElse\"], [\"mic\", \"\"], [4, \"ngIf\"], [1, \"speech-result-width\"], [\"matInput\", \"\", \"placeholder\", \"Speech Input Result\", \"rows\", \"15\", \"disabled\", \"true\", 3, \"value\"], [\"matInput\", \"\", \"placeholder\", \"Speech Output Result\", \"rows\", \"15\", \"disabled\", \"true\", 3, \"value\"], [1, \"notification\"], [3, \"value\", \"click\"], [\"mat-fab\", \"\", 3, \"click\"], [1, \"soundwave\"], [1, \"notification\", \"mat-elevation-z4\"]],\n    template: function WebSpeechComponent_Template(rf, ctx) {\n      if (rf & 1) {\n        i0.ɵɵelementStart(0, \"section\");\n        i0.ɵɵtemplate(1, WebSpeechComponent_mat_card_1_Template, 2, 1, \"mat-card\", 0);\n        i0.ɵɵpipe(2, \"async\");\n        i0.ɵɵelementEnd();\n        i0.ɵɵelementStart(3, \"section\")(4, \"mat-form-field\")(5, \"mat-label\");\n        i0.ɵɵtext(6, \"Select your language\");\n        i0.ɵɵelementEnd();\n        i0.ɵɵelementStart(7, \"mat-select\", 1);\n        i0.ɵɵlistener(\"valueChange\", function WebSpeechComponent_Template_mat_select_valueChange_7_listener($event) {\n          return ctx.currentLanguage = $event;\n        });\n        i0.ɵɵtemplate(8, WebSpeechComponent_mat_option_8_Template, 2, 2, \"mat-option\", 2);\n        i0.ɵɵelementEnd()()();\n        i0.ɵɵelementStart(9, \"section\");\n        i0.ɵɵtemplate(10, WebSpeechComponent_button_10_Template, 3, 0, \"button\", 3);\n        i0.ɵɵpipe(11, \"async\");\n        i0.ɵɵtemplate(12, WebSpeechComponent_ng_template_12_Template, 3, 0, \"ng-template\", null, 4, i0.ɵɵtemplateRefExtractor);\n        i0.ɵɵelementEnd();\n        i0.ɵɵtemplate(14, WebSpeechComponent_section_14_Template, 4, 3, \"section\", 5);\n        i0.ɵɵpipe(15, \"async\");\n        i0.ɵɵelementStart(16, \"section\")(17, \"mat-form-field\", 6);\n        i0.ɵɵelement(18, \"textarea\", 7);\n        i0.ɵɵelementEnd()();\n        i0.ɵɵelementStart(19, \"section\")(20, \"mat-form-field\", 6);\n        i0.ɵɵelement(21, \"textarea\", 8);\n        i0.ɵɵelementEnd()();\n      }\n\n      if (rf & 2) {\n        const _r3 = i0.ɵɵreference(13);\n\n        i0.ɵɵadvance(1);\n        i0.ɵɵproperty(\"ngIf\", i0.ɵɵpipeBind1(2, 8, ctx.errorMessage$));\n        i0.ɵɵadvance(6);\n        i0.ɵɵproperty(\"value\", ctx.currentLanguage);\n        i0.ɵɵadvance(1);\n        i0.ɵɵproperty(\"ngForOf\", ctx.languages);\n        i0.ɵɵadvance(2);\n        i0.ɵɵproperty(\"ngIf\", i0.ɵɵpipeBind1(11, 10, ctx.listening$))(\"ngIfElse\", _r3);\n        i0.ɵɵadvance(4);\n        i0.ɵɵproperty(\"ngIf\", i0.ɵɵpipeBind1(15, 12, ctx.transcript$));\n        i0.ɵɵadvance(4);\n        i0.ɵɵproperty(\"value\", ctx.totalTranscript || \"\");\n        i0.ɵɵadvance(3);\n        i0.ɵɵproperty(\"value\", ctx.totalResult || \"\");\n      }\n    },\n    dependencies: [i4.NgForOf, i4.NgIf, i5.MatButton, i6.MatCard, i7.MatFormField, i7.MatLabel, i8.MatInput, i9.MatIcon, i10.MatSelect, i11.MatOption, i4.AsyncPipe],\n    styles: [\".speech-result-width[_ngcontent-%COMP%]{width:100%}textarea[_ngcontent-%COMP%]{text-align:justify;text-align-last:center}section[_ngcontent-%COMP%]{padding:15px;text-align:center}.mat-input-element[_ngcontent-%COMP%]:disabled{color:#000000e6}.notification[_ngcontent-%COMP%]{margin-left:20px;margin-right:20px}.soundwave[_ngcontent-%COMP%]{animation:soundwave .7s infinite}@keyframes soundwave{0%{opacity:.5;color:#fff}20%{color:#fff;opacity:.6}35%{color:#fff;opacity:.9}45%{color:#fff;opacity:1}55%{color:#fff;opacity:.9}to{color:#fff;opacity:.5}}\"],\n    changeDetection: 0\n  });\n  return WebSpeechComponent;\n})();","map":null,"metadata":{},"sourceType":"module"}